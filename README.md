CycleGAN-Face-Sketch-SynthesisProject OverviewThis project implements a Cycle-Consistent Adversarial Network (CycleGAN) designed for high-fidelity, bidirectional image-to-image translation between human portraits and artistic sketches. Using the Person Face Sketches dataset, the system facilitates the conversion of real-world photographs into sketches and reconstructs realistic faces from hand-drawn inputs. The implementation emphasizes computational efficiency through an optimized model architecture and an end-to-end deployment pipeline using Flask and Ngrok.üöÄ FeaturesBidirectional Translation: Seamlessly converts Photo ‚Üí Sketch and Sketch ‚Üí Photo using a unified model framework.Optimized Architecture: Features a ResNet-based Generator with reduced residual blocks (3 blocks) and a PatchGAN Discriminator for faster training on consumer-grade GPUs.Automated Domain Detection: The backend automatically detects whether the input is a sketch or a photo based on pixel intensity and applies the appropriate transformation.Real-time Web Interface: A user-friendly Flask UI integrated with Ngrok for public access and instant inference testing.Memory-Efficient Training: Optimized for $128 \times 128$ resolution to manage memory constraints while preserving key facial features.üõ†Ô∏è Tech StackFramework: PyTorchArchitecture: CycleGAN (Generators + Discriminators)Deployment: Flask, PyNgrokEnvironment: Google Colab (T4 GPU)Data Processing: Torchvision, PILüèóÔ∏è Model ArchitectureGeneratorBackbone: Encoder-Decoder structure with 3 ResNet blocks for feature preservation.Normalization: Uses InstanceNorm2d for style-invariant normalization.Activation: Tanh activation at the output layer to scale pixel values correctly.DiscriminatorArchitecture: PatchGAN architecture designed to classify $70 \times 70$ image patches.Layers: Utilizes LeakyReLU and Conv2d layers to distinguish local textures (strokes vs. skin).Loss FunctionsAdversarial Loss: Least Squares GAN (MSELoss) for improved training stability.Cycle Consistency Loss: L1 Loss to ensure $G_{B2A}(G_{A2B}(x)) \approx x$.Identity Loss: L1 Loss weighted at $\lambda = 5$ to preserve color and compositional integrity.üìä Dataset & TrainingThe model is trained on the Person Face Sketches dataset.Training Samples: Optimized for speed using 500 images per domain.Image Pre-processing: Resized to $128 \times 128$ and normalized to the range $[-1, 1]$.Performance: Achieved training throughput of approximately 10.84 iterations per second.üíª Usage1. TrainingRun the q1_A-02_Gen-AI.ipynb in Google Colab. Ensure your Google Drive is mounted to save checkpoints automatically to /content/drive/MyDrive/Checkpoints_CycleGAN_Fast.2. Inference (Web UI)Navigate to the Flask app section in the notebook.Input your NGROK_AUTH_TOKEN to initiate the tunnel.Launch the app to generate a Public URL.Upload any image; the system will auto-detect the domain and display the converted result in real-time.üìÇ Repository Structureq1_A-02_Gen-AI.ipynb: Full source code for training and deployment.templates/: HTML templates for the Flask web interface.static/: Directories for storing uploads and results.
