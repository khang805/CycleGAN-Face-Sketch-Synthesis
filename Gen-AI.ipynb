{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtLr12YJ-Xoc",
        "outputId": "35ed4b6a-f34a-4d54-e84b-70eb758f8f0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [05:41<00:00,  1.46it/s, G=4.64]\n",
            "Epoch 2/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:46<00:00, 10.66it/s, G=4.42]\n",
            "Epoch 3/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:46<00:00, 10.64it/s, G=4.2]\n",
            "Epoch 4/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:46<00:00, 10.85it/s, G=3.48]\n",
            "Epoch 5/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:47<00:00, 10.50it/s, G=3.54]\n",
            "Epoch 6/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:47<00:00, 10.59it/s, G=3.76]\n",
            "Epoch 7/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:46<00:00, 10.67it/s, G=4.2]\n",
            "Epoch 8/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:46<00:00, 10.70it/s, G=3.05]\n",
            "Epoch 9/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:47<00:00, 10.59it/s, G=3.37]\n",
            "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:46<00:00, 10.84it/s, G=3.54]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ‰ FINAL MODEL SAVED!\n"
          ]
        }
      ],
      "source": [
        "# ===============================================================\n",
        "# FAST CycleGAN for Face <-> Sketch (Optimized for Google Colab)\n",
        "# ===============================================================\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import itertools\n",
        "\n",
        "# ===============================================================\n",
        "# Google Drive\n",
        "# ===============================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "BASE_PATH = '/content/drive/MyDrive/Dataset_Q1_A-01_Gen-AI'\n",
        "\n",
        "# ===============================================================\n",
        "# SPEED-UP OPTION: Use only first N images\n",
        "# ===============================================================\n",
        "MAX_IMAGES = 500      # Reduce if still slow\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# Dataset Class\n",
        "# ===============================================================\n",
        "class FaceSketchDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "\n",
        "        self.photo_dir = os.path.join(root_dir, 'photos')\n",
        "        self.sketch_dir = os.path.join(root_dir, 'sketches')\n",
        "\n",
        "        self.photo_images = sorted([f for f in os.listdir(self.photo_dir) if f.endswith('.jpg')])\n",
        "        self.sketch_images = sorted([f for f in os.listdir(self.sketch_dir) if f.endswith('.jpg')])\n",
        "\n",
        "        # Speed: limit N images\n",
        "        self.photo_images = self.photo_images[:MAX_IMAGES]\n",
        "        self.sketch_images = self.sketch_images[:MAX_IMAGES]\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.photo_images), len(self.sketch_images))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        photo = Image.open(os.path.join(self.photo_dir, self.photo_images[idx])).convert('RGB')\n",
        "        sketch = Image.open(os.path.join(self.sketch_dir, self.sketch_images[idx])).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            photo = self.transform(photo)\n",
        "            sketch = self.transform(sketch)\n",
        "\n",
        "        return {\"photo\": photo, \"sketch\": sketch}\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# Transformations (Speed: 256 â†’ 128)\n",
        "# ===============================================================\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "# ===============================================================\n",
        "# Generators (Speed: residual blocks from 9 â†’ 3)\n",
        "# ===============================================================\n",
        "\n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(dim, dim, 3, padding=1),\n",
        "            nn.InstanceNorm2d(dim),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Conv2d(dim, dim, 3, padding=1),\n",
        "            nn.InstanceNorm2d(dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_nc, output_nc, n_blocks=3):  # SPEED OPT\n",
        "        super().__init__()\n",
        "        model = [\n",
        "            nn.Conv2d(input_nc, 64, 7, padding=3),\n",
        "            nn.InstanceNorm2d(64),\n",
        "            nn.ReLU(True)\n",
        "        ]\n",
        "\n",
        "        # down\n",
        "        in_f = 64\n",
        "        out_f = 128\n",
        "        model += [\n",
        "            nn.Conv2d(in_f, out_f, 3, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(out_f),\n",
        "            nn.ReLU(True)\n",
        "        ]\n",
        "\n",
        "        in_f = out_f\n",
        "        out_f = 256\n",
        "        model += [\n",
        "            nn.Conv2d(in_f, out_f, 3, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(out_f),\n",
        "            nn.ReLU(True)\n",
        "        ]\n",
        "\n",
        "        in_f = out_f\n",
        "\n",
        "        # residual\n",
        "        for _ in range(n_blocks):\n",
        "            model += [ResnetBlock(in_f)]\n",
        "\n",
        "        # up\n",
        "        out_f = in_f // 2\n",
        "        model += [\n",
        "            nn.ConvTranspose2d(in_f, out_f, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.InstanceNorm2d(out_f),\n",
        "            nn.ReLU(True)\n",
        "        ]\n",
        "\n",
        "        in_f = out_f\n",
        "        out_f = in_f // 2\n",
        "        model += [\n",
        "            nn.ConvTranspose2d(in_f, out_f, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.InstanceNorm2d(out_f),\n",
        "            nn.ReLU(True)\n",
        "        ]\n",
        "\n",
        "        model += [\n",
        "            nn.Conv2d(out_f, output_nc, 7, padding=3),\n",
        "            nn.Tanh()\n",
        "        ]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# PatchGAN Discriminator\n",
        "# ===============================================================\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_nc):\n",
        "        super().__init__()\n",
        "        model = [\n",
        "            nn.Conv2d(input_nc, 64, 4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        ]\n",
        "\n",
        "        in_f = 64\n",
        "        out_f = 128\n",
        "        model += [\n",
        "            nn.Conv2d(in_f, out_f, 4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(out_f),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        ]\n",
        "\n",
        "        in_f = out_f\n",
        "        out_f = 256\n",
        "        model += [\n",
        "            nn.Conv2d(in_f, out_f, 4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(out_f),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        ]\n",
        "\n",
        "        model += [nn.Conv2d(out_f, 1, 4, padding=1)]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# Device\n",
        "# ===============================================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "G_A2B = Generator(3, 3).to(device)\n",
        "G_B2A = Generator(3, 3).to(device)\n",
        "D_A = Discriminator(3).to(device)\n",
        "D_B = Discriminator(3).to(device)\n",
        "\n",
        "# ===============================================================\n",
        "# Loss & Optimizers\n",
        "# ===============================================================\n",
        "adv_loss = nn.MSELoss()\n",
        "cycle_loss_fn = nn.L1Loss()\n",
        "id_loss_fn = nn.L1Loss()\n",
        "\n",
        "optimizer_G = optim.Adam(\n",
        "    itertools.chain(G_A2B.parameters(), G_B2A.parameters()),\n",
        "    lr=0.0002, betas=(0.5, 0.999)\n",
        ")\n",
        "optimizer_D_A = optim.Adam(D_A.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D_B = optim.Adam(D_B.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# Loaders\n",
        "# ===============================================================\n",
        "train_dataset = FaceSketchDataset(os.path.join(BASE_PATH, \"train\"), transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "val_dataset = FaceSketchDataset(os.path.join(BASE_PATH, \"val\"), transform)\n",
        "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# ===============================================================\n",
        "# Checkpoint\n",
        "# ===============================================================\n",
        "ckpt_dir = \"/content/drive/MyDrive/Checkpoints_CycleGAN_Fast\"\n",
        "os.makedirs(ckpt_dir, exist_ok=True)\n",
        "\n",
        "best_val = float(\"inf\")\n",
        "\n",
        "# ===============================================================\n",
        "# Training\n",
        "# ===============================================================\n",
        "EPOCHS = 10          # now you can train more because it's fast\n",
        "lambda_cycle = 10\n",
        "lambda_identity = 5\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    loop = tqdm(train_loader)\n",
        "\n",
        "    for batch in loop:\n",
        "        real_A = batch['photo'].to(device)\n",
        "        real_B = batch['sketch'].to(device)\n",
        "\n",
        "        # ============================================\n",
        "        # Train Generators\n",
        "        # ============================================\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        fake_B = G_A2B(real_A)\n",
        "        fake_A = G_B2A(real_B)\n",
        "\n",
        "        # GAN Loss\n",
        "        loss_GAN = adv_loss(D_B(fake_B), torch.ones_like(D_B(fake_B))) + \\\n",
        "                   adv_loss(D_A(fake_A), torch.ones_like(D_A(fake_A)))\n",
        "\n",
        "        # Cycle loss\n",
        "        rec_A = G_B2A(fake_B)\n",
        "        rec_B = G_A2B(fake_A)\n",
        "        loss_cycle = cycle_loss_fn(rec_A, real_A) + cycle_loss_fn(rec_B, real_B)\n",
        "\n",
        "        # Identity\n",
        "        loss_id = id_loss_fn(G_A2B(real_B), real_B) + id_loss_fn(G_B2A(real_A), real_A)\n",
        "\n",
        "        # Total\n",
        "        loss_G = loss_GAN + lambda_cycle * loss_cycle + lambda_identity * loss_id\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ============================================\n",
        "        # Train D_A\n",
        "        # ============================================\n",
        "        optimizer_D_A.zero_grad()\n",
        "        loss_D_A = (adv_loss(D_A(real_A), torch.ones_like(D_A(real_A))) +\n",
        "                    adv_loss(D_A(fake_A.detach()), torch.zeros_like(D_A(fake_A))))\n",
        "        loss_D_A.backward()\n",
        "        optimizer_D_A.step()\n",
        "\n",
        "        # ============================================\n",
        "        # Train D_B\n",
        "        # ============================================\n",
        "        optimizer_D_B.zero_grad()\n",
        "        loss_D_B = (adv_loss(D_B(real_B), torch.ones_like(D_B(real_B))) +\n",
        "                    adv_loss(D_B(fake_B.detach()), torch.zeros_like(D_B(fake_B))))\n",
        "        loss_D_B.backward()\n",
        "        optimizer_D_B.step()\n",
        "\n",
        "        loop.set_description(f\"Epoch {epoch}/{EPOCHS}\")\n",
        "        loop.set_postfix(G=loss_G.item())\n",
        "\n",
        "    # ===========================================================\n",
        "    # SAVE MODEL EACH EPOCH\n",
        "    # ===========================================================\n",
        "    torch.save({\n",
        "        \"G_A2B\": G_A2B.state_dict(),\n",
        "        \"G_B2A\": G_B2A.state_dict(),\n",
        "        \"D_A\": D_A.state_dict(),\n",
        "        \"D_B\": D_B.state_dict(),\n",
        "    }, f\"{ckpt_dir}/epoch_{epoch}.pth\")\n",
        "\n",
        "    # ===========================================================\n",
        "    # VALIDATION\n",
        "    # ===========================================================\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            A = batch['photo'].to(device)\n",
        "            B = batch['sketch'].to(device)\n",
        "\n",
        "            recA = G_B2A(G_A2B(A))\n",
        "            recB = G_A2B(G_B2A(B))\n",
        "\n",
        "            loss = cycle_loss_fn(recA, A) + cycle_loss_fn(recB, B)\n",
        "            total += loss.item()\n",
        "\n",
        "    avg = total / len(val_loader)\n",
        "\n",
        "    if avg < best_val:\n",
        "        best_val = avg\n",
        "        torch.save({\n",
        "            \"G_A2B\": G_A2B.state_dict(),\n",
        "            \"G_B2A\": G_B2A.state_dict(),\n",
        "        }, f\"{ckpt_dir}/best_model.pth\")\n",
        "\n",
        "# ===============================================================\n",
        "# SAVE FINAL MODEL FOR UI\n",
        "# ===============================================================\n",
        "torch.save({\n",
        "    \"G_A2B\": G_A2B.state_dict(),\n",
        "    \"G_B2A\": G_B2A.state_dict(),\n",
        "}, f\"{ckpt_dir}/final_model.pth\")\n",
        "\n",
        "print(\"ðŸŽ‰ FINAL MODEL SAVED!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "path = \"/content/drive/MyDrive/Checkpoints_CycleGAN_Fast/final_model.pth\"\n",
        "ckpt = torch.load(path, map_location=\"cpu\")\n",
        "\n",
        "print(\"Keys:\", ckpt.keys())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqfsBtjqSNBl",
        "outputId": "4f2ad788-150b-465f-df63-bede7d2e1bae"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys: dict_keys(['G_A2B', 'G_B2A'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(\"templates\", exist_ok=True)\n",
        "os.makedirs(\"static/uploads\", exist_ok=True)\n",
        "os.makedirs(\"static/results\", exist_ok=True)\n",
        "os.makedirs(\"model\", exist_ok=True)\n"
      ],
      "metadata": {
        "id": "QLXtKscPUbQA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if os.path.exists(\"templates/index.html\"):\n",
        "    print(\"âœ… index.html exists!\")\n",
        "else:\n",
        "    print(\"âŒ index.html NOT found!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F3Q-J6LVsXb",
        "outputId": "1a64cd05-8ef5-45ca-915c-33ad3963eabc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… index.html exists!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Setup ngrok with your token\n",
        "# ================================\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Replace this with your token\n",
        "NGROK_AUTH_TOKEN = \"34nHRQEhWsyECIuOzxFeuaoJFyn_qNnJCPo47LWrPKwpsBKc\"\n",
        "\n",
        "# Set your authtoken\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# Start tunnel\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\"ðŸš€ Public URL:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQw-MVeCYOnY",
        "outputId": "ddc87b27-9f13-4c5b-e777-2fce0077bbac"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Public URL: NgrokTunnel: \"https://alexandria-contestable-piper.ngrok-free.dev\" -> \"http://localhost:5000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Install required packages\n",
        "# ================================\n",
        "!pip install flask pyngrok pillow torch torchvision\n",
        "\n",
        "# ================================\n",
        "# Imports\n",
        "# ================================\n",
        "import os\n",
        "import io\n",
        "import base64\n",
        "from flask import Flask, render_template, request\n",
        "from pyngrok import ngrok\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "\n",
        "# ================================\n",
        "# Create templates folder\n",
        "# ================================\n",
        "os.makedirs(\"templates\", exist_ok=True)\n",
        "\n",
        "# ================================\n",
        "# index.html template\n",
        "# ================================\n",
        "index_html = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Face <-> Sketch Converter</title>\n",
        "</head>\n",
        "<body>\n",
        "    <h2>Upload a Photo or Sketch</h2>\n",
        "    <form method=\"POST\" enctype=\"multipart/form-data\" action=\"/convert\">\n",
        "        <input type=\"file\" name=\"file\" required>\n",
        "        <button type=\"submit\">Convert</button>\n",
        "    </form>\n",
        "\n",
        "    {% if result_img %}\n",
        "    <h3>Result:</h3>\n",
        "    <img src=\"{{ result_img }}\" width=\"256\">\n",
        "    {% endif %}\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "with open(\"templates/index.html\", \"w\") as f:\n",
        "    f.write(index_html)\n",
        "\n",
        "# ================================\n",
        "# Flask app\n",
        "# ================================\n",
        "app = Flask(__name__)\n",
        "\n",
        "# ================================\n",
        "# Device\n",
        "# ================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ================================\n",
        "# Define Model (Resnet + Generator)\n",
        "# ================================\n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(dim, dim, 3, padding=1),\n",
        "            nn.InstanceNorm2d(dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(dim, dim, 3, padding=1),\n",
        "            nn.InstanceNorm2d(dim)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_nc, output_nc, n_blocks=3):\n",
        "        super().__init__()\n",
        "        model = [nn.Conv2d(input_nc, 64, 7, padding=3),\n",
        "                 nn.InstanceNorm2d(64),\n",
        "                 nn.ReLU(True)]\n",
        "        in_f, out_f = 64, 128\n",
        "        model += [nn.Conv2d(in_f, out_f, 3, stride=2, padding=1),\n",
        "                  nn.InstanceNorm2d(out_f),\n",
        "                  nn.ReLU(True)]\n",
        "        in_f = out_f\n",
        "        out_f = 256\n",
        "        model += [nn.Conv2d(in_f, out_f, 3, stride=2, padding=1),\n",
        "                  nn.InstanceNorm2d(out_f),\n",
        "                  nn.ReLU(True)]\n",
        "        in_f = out_f\n",
        "        for _ in range(n_blocks):\n",
        "            model += [ResnetBlock(in_f)]\n",
        "        out_f = in_f // 2\n",
        "        model += [nn.ConvTranspose2d(in_f, out_f, 3, stride=2, padding=1, output_padding=1),\n",
        "                  nn.InstanceNorm2d(out_f),\n",
        "                  nn.ReLU(True)]\n",
        "        in_f = out_f\n",
        "        out_f = in_f // 2\n",
        "        model += [nn.ConvTranspose2d(in_f, out_f, 3, stride=2, padding=1, output_padding=1),\n",
        "                  nn.InstanceNorm2d(out_f),\n",
        "                  nn.ReLU(True)]\n",
        "        model += [nn.Conv2d(out_f, output_nc, 7, padding=3), nn.Tanh()]\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# ================================\n",
        "# Initialize & Load Models\n",
        "# ================================\n",
        "G_A2B = Generator(3,3).to(device)\n",
        "G_B2A = Generator(3,3).to(device)\n",
        "\n",
        "ckpt_path = \"/content/drive/MyDrive/Checkpoints_CycleGAN_Fast/final_model.pth\"\n",
        "checkpoint = torch.load(ckpt_path, map_location=device)\n",
        "G_A2B.load_state_dict(checkpoint[\"G_A2B\"])\n",
        "G_B2A.load_state_dict(checkpoint[\"G_B2A\"])\n",
        "G_A2B.eval()\n",
        "G_B2A.eval()\n",
        "\n",
        "# ================================\n",
        "# Image Transform\n",
        "# ================================\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128,128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "])\n",
        "\n",
        "def tensor_to_pil(tensor):\n",
        "    tensor = tensor.squeeze(0).cpu().detach()\n",
        "    tensor = (tensor + 1)/2\n",
        "    tensor = tensor.clamp(0,1)\n",
        "    return transforms.ToPILImage()(tensor)\n",
        "\n",
        "# ================================\n",
        "# Flask Routes\n",
        "# ================================\n",
        "@app.route(\"/\", methods=[\"GET\"])\n",
        "def home():\n",
        "    return render_template(\"index.html\", result_img=None)\n",
        "\n",
        "@app.route(\"/convert\", methods=[\"POST\"])\n",
        "def convert():\n",
        "    file = request.files[\"file\"]\n",
        "    img = Image.open(file).convert(\"RGB\")\n",
        "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    avg_intensity = img_tensor.mean().item()\n",
        "    with torch.no_grad():\n",
        "        if avg_intensity < 0.5:\n",
        "            output = G_B2A(img_tensor)\n",
        "        else:\n",
        "            output = G_A2B(img_tensor)\n",
        "\n",
        "    out_img = tensor_to_pil(output)\n",
        "    buf = io.BytesIO()\n",
        "    out_img.save(buf, format=\"PNG\")\n",
        "    img_base64 = base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "    return render_template(\"index.html\", result_img=\"data:image/png;base64,\" + img_base64)\n",
        "\n",
        "# ================================\n",
        "# Start Flask via Ngrok\n",
        "# ================================\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\"ðŸš€ Public URL:\", public_url)\n",
        "app.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIGhl3B5V_Fg",
        "outputId": "a201406a-09d5-444f-ee07-cbbcfe2b60d3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.5.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "ðŸš€ Public URL: NgrokTunnel: \"https://alexandria-contestable-piper.ngrok-free.dev\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Nov/2025 05:27:43] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Nov/2025 05:27:54] \"POST /convert HTTP/1.1\" 200 -\n",
            "WARNING:pyngrok.process.ngrok:t=2025-11-25T05:28:04+0000 lvl=warn msg=\"Stopping forwarder\" name=http-5000-4b0bb2a7-3e2e-44f2-9ce4-aaeb7e9cdbb8 acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        }
      ]
    }
  ]
}